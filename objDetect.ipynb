{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "import face_recognition\n",
    "import collections\n",
    "\n",
    "# Load YOLOv8 model for person detection\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# Initialize DeepSORT tracker with optimized parameters\n",
    "tracker = DeepSort(max_age=100)  # Increased max_age to reduce flickering\n",
    "\n",
    "# Confidence threshold for filtering detections\n",
    "CONFIDENCE_THRESHOLD = 0.4  \n",
    "\n",
    "# Dictionaries for face encoding storage and global tracking\n",
    "face_db = {}\n",
    "global_person_db = {}\n",
    "\n",
    "# Track history for bounding box smoothing\n",
    "track_history = collections.defaultdict(list)\n",
    "\n",
    "# Load video sources (change as per requirement)\n",
    "video_sources = [1,2]  # Replace with RTSP URLs for live feeds\n",
    "caps = [cv2.VideoCapture(src) for src in video_sources]\n",
    "\n",
    "frame_count = 0  # Counter to optimize face recognition\n",
    "\n",
    "# Function to extract face encoding from a bounding box\n",
    "def get_face_encoding(frame, bbox):\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    face = frame[y1:y2, x1:x2]\n",
    "    if face.size == 0:  # Ensure face is valid\n",
    "        return None\n",
    "    rgb_face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "    encodings = face_recognition.face_encodings(rgb_face)\n",
    "    return encodings[0] if encodings else None\n",
    "\n",
    "# Function to smooth bounding box movements\n",
    "def smooth_position(track_id, new_bbox):\n",
    "    track_history[track_id].append(new_bbox)\n",
    "    if len(track_history[track_id]) > 5:  # Keep last 5 positions\n",
    "        track_history[track_id].pop(0)\n",
    "    \n",
    "    avg_x1 = sum(b[0] for b in track_history[track_id]) // len(track_history[track_id])\n",
    "    avg_y1 = sum(b[1] for b in track_history[track_id]) // len(track_history[track_id])\n",
    "    avg_x2 = sum(b[2] for b in track_history[track_id]) // len(track_history[track_id])\n",
    "    avg_y2 = sum(b[3] for b in track_history[track_id]) // len(track_history[track_id])\n",
    "    \n",
    "    return avg_x1, avg_y1, avg_x2, avg_y2\n",
    "\n",
    "# Function to process a single frame\n",
    "def process_frame(frame, cam_id):\n",
    "    global frame_count\n",
    "    frame_count += 1  # Increment frame counter\n",
    "\n",
    "    detections = []\n",
    "    results = model(frame)\n",
    "\n",
    "    # Extract bounding boxes from YOLO results\n",
    "    for box, conf, cls in zip(results[0].boxes.xyxy, results[0].boxes.conf, results[0].boxes.cls):\n",
    "        x1, y1, x2, y2 = map(int, box.tolist())\n",
    "        conf = float(conf)\n",
    "        cls = int(cls)\n",
    "\n",
    "        if cls == 0 and conf > CONFIDENCE_THRESHOLD:  # Detect only people\n",
    "            detections.append([(x1, y1, x2, y2), conf])\n",
    "\n",
    "    # Update tracker\n",
    "    tracks = tracker.update_tracks(detections, frame=frame)\n",
    "\n",
    "    tracked_info = []\n",
    "    for track in tracks:\n",
    "        if not track.is_confirmed():\n",
    "            continue\n",
    "\n",
    "        track_id = track.track_id\n",
    "        x, y, w, h = map(int, track.to_tlwh())  # Convert to bounding box\n",
    "        x2, y2 = x + w, y + h  # Convert to (x1, y1, x2, y2)\n",
    "\n",
    "        # Optimize face recognition every 10 frames\n",
    "        if frame_count % 10 == 0 and track_id not in face_db:\n",
    "            face_encoding = get_face_encoding(frame, (x, y, x2, y2))\n",
    "            if face_encoding is not None:\n",
    "                face_db[track_id] = face_encoding\n",
    "\n",
    "        # Register person in global tracking database\n",
    "        if track_id not in global_person_db:\n",
    "            global_person_db[track_id] = cam_id\n",
    "\n",
    "        tracked_info.append((x, y, x2, y2, track_id))\n",
    "\n",
    "    return frame, tracked_info\n",
    "\n",
    "# Main loop to process video feeds\n",
    "while True:\n",
    "    for i, cap in enumerate(caps):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "\n",
    "        processed_frame, tracked_objects = process_frame(frame, cam_id=i)\n",
    "\n",
    "        # Draw bounding boxes with smoothing\n",
    "        for x1, y1, x2, y2, track_id in tracked_objects:\n",
    "            x1, y1, x2, y2 = smooth_position(track_id, (x1, y1, x2, y2))\n",
    "            cv2.rectangle(processed_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(processed_frame, f\"ID {track_id}\", (x1, y1 - 5), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        # Display real-time tracking\n",
    "        cv2.imshow(f\"Camera {i+1}\", processed_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # Press 'Q' to exit\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "for cap in caps:\n",
    "    cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
